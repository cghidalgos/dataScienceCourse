{"cells":[{"cell_type":"markdown","metadata":{"id":"nllzO1YP2D9G"},"source":["# Taller 3 - Red de Monitoreo de Calidad del Aire de Bogota.\n","\n","\n","http://rmcab.ambientebogota.gov.co/Report/stationreport\n","\n","\n","La calidad de aire es un problema crítico en las grandes ciudades del mundo. Varias afecciones respiratorias están relacionadas con la calidad del aire que respiramos y por tanto, es importante para las autoridades locales medir, reportar y predecir de manera constante y precisa los niveles de los diferentes contaminantes presentes en el aire de la ciudad. Por esta razón, la secretaría distrital de ambiente de Bogotá instaló 19 estaciones de monitoreo de aire en la ciudad y proporciona de manera libre estos datos para que cualquiera pueda hacer uso de esta información.\n","Uno de los contaminantes más peligrosos para la salud humana es el material particulado de tamaño 9 menor a 2.5 micras (PM2.5) ya que se acumula en los pulmones y puede causar daños permanentes a quienes están expuestos a él  por largos periodos de tiempo. \n","Al analizar los datos provenientes de las estaciones de monitoreo, se han identificado varios problemas asociados a la calidad de los datos y a la fiabilidad de la información. Por ejemplo se ha identificado que más del 20% de los datos correspondientes a las mediciones de dicho contaminante están perdidas. Esto es un fenomeno común, ya que es común que los sensores de las diferentes estanciones fallén por diversos motivos, como cortes de energía, periodos de mantenimiento preventivo y reparaciones efectuadas a las estaciones. \n","Adicionalmente, el área que cubren los sensores es muy pequeña comparada con el área de una ciudad como Bogotá. Entonces se necesitan modelos que permitan informar a la ciudadanía sobre los niveles de contaniminazión aún en áreas que no cuentan con sensores. Incluso, si los datos son de muy buena calidad, podemos crear modelos que predigan la calidad del aire en periodos de tiempo futuros.\n","\n","En esta sección se realiza una bodega de datos  que contine 68.000 registros de la calidad del aire de la ciudad de Bogotá.  La bodega de datos, se conecta con el lenguaje de programción Python para hacer procesamiento de datos y luego mostrar la infromacion usando librerias de datos. \n"]},{"cell_type":"markdown","metadata":{"id":"gudh22kB2D9J"},"source":["## Descripción de los datos "]},{"cell_type":"markdown","metadata":{"_cell_guid":"a46b6c64-6f25-4007-9f41-4abd863b0130","_uuid":"db8d6c6327671959fae8eefb9e3e60adad46afbe","id":"EclXh3ZcfaL5"},"source":["## 1. Cargar Librerias\n","***"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9b79a352-5901-4b5a-af72-c2872c6c2d3b","_uuid":"4ebdadf89270fbbe8a2efa6aa8053c3605fbc808","id":"fbYd1fhmfaL5","tags":[]},"outputs":[],"source":["# Carga las librerias necesarias"]},{"cell_type":"markdown","metadata":{"id":"-6CGZ7d4duEW"},"source":["## 2. Cargar Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af5af896-7e0a-46fb-837a-b6f0ae51fd56","_uuid":"4bbc946c081a0d297fd5801048e9b49a0d036168","colab":{"base_uri":"https://localhost:8080/","height":424},"id":"znzvPbRNfaL7","outputId":"addc8ec6-7f09-41d1-a14c-c65d8b760908","tags":[]},"outputs":[],"source":["#dataframe nombrado \"df\"\n","\n","#cargar conjunto de datos ../Taller1/data/dataset_with_geo_missing.csv\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"11e56653-4ce4-44eb-b562-a5715562c3cc","_uuid":"7af6d7934b3f0212c93d1a07e69f934dd986a954","id":"uxgCcL_NfaMB","tags":[]},"source":["## 3: Explorar datos\n","*** "]},{"cell_type":"markdown","metadata":{"_cell_guid":"bde6fe00-926c-4ee4-a00a-faca5ecfa917","_uuid":"551ca8d64aaaa080d36e0da0ed46c3ca267349fd","id":"_8yxy0XofaMC"},"source":["###  3.1 Estadisticas \n","***\n","Resumen: \n","- Identificar nombre de las columnas\n","- Número de columnas y filas \n","- Tamaño del conjunto de datos\n","- Tipos de datos\n","- Porcentajes de valores\n","- Correlaciones de variables\n","- Valores nulos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjvJn1gqxEWd","outputId":"c155ac5c-40c8-48b8-d888-6568d8c44d68"},"outputs":[],"source":["#nombre de las columnas \n","df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bc3d99b1-7bc5-4ba2-a34f-0a721c51075f","_uuid":"a9ae5674c17ee2b88035aef24d674c56d0b89a03","colab":{"base_uri":"https://localhost:8080/","height":344},"id":"PjvcTK_ZfaMD","outputId":"8cb798ef-3de4-4a8f-f9ab-4de8cd60371e"},"outputs":[],"source":["# Estadisticas basicas del conjunto de datos \n","df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73419440-c92d-4f6a-a718-216646b900cc","_uuid":"a7eabf82ee6adbd09aca9e878112f8525ea50417","colab":{"base_uri":"https://localhost:8080/"},"id":"TqxYdlGofaMC","outputId":"9c6c3444-4b5b-4673-ffc3-a8c8876dd91e"},"outputs":[],"source":["#Descripción del conjunto de datos: 166440 observaciones y 10 caracteristicas\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25bc8dfe-5d24-4249-bab0-0424a20b1bd5","_uuid":"4be89ba5d2e7f693b0cd228830423a700b6196fa","colab":{"base_uri":"https://localhost:8080/"},"id":"GvztrHwefaMC","outputId":"631536e2-5ec1-4d0b-f0a2-bf8ae47f2fe0"},"outputs":[],"source":["# Comprobar el número de Filas y Columnas \n","print(\"Número de  Filas: \", len(df))\n","print(\"Número de Columnas \", + len(df.columns))\n","\n","#Comprobar el tipo de datos en las características\n","print(df.dtypes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKhzqKC5n9oG"},"outputs":[],"source":["#Comprobar si hay valores nulos true o false\n","#df.isnull().any(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Aa0OGCYlOsJf","scrolled":true},"outputs":[],"source":["# Esta celda eliminará todas las filas que tienen valores nulos\n","#target = 'PM2.5'\n","#df.dropna(subset=[target], inplace=True)\n","#df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d61efd5d-5c2c-4b3c-b2ac-22d562c9e91a","_uuid":"cfb764723207606d3e7fe991b17cd648e04c0a7a","colab":{"base_uri":"https://localhost:8080/","height":143},"id":"LN-uwGOPfaMD","outputId":"18973e51-a24c-4621-abc8-5f874f301e71"},"outputs":[],"source":["# Resumen de una variable (False V.S. True) en la variable Status\n","Status_Summary = df.groupby('Status')\n","Status_Summary.mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JD_8dbJSzZj3","outputId":"7d595b85-04b8-4205-a8fd-533ba3f245fe"},"outputs":[],"source":["#Filtrar datos por columnas\n","df['Status'] = df['PM2.5']>12\n","df.Status.value_counts()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"918f20ff-ed2c-43dd-849c-b7d751aeed86","_uuid":"bed79decbf6495197f8f0219212c41c0042e196e","id":"BI1_I-gLfaME"},"source":["####  3.1.1 Correlación\n","***\n","\n","Resumen:\n","\n","\n","- Hay una correlación **positiva(+) a 1** o **negativa(-) a -1** hay una correlacion fuerte. La aproximación a 0 es mas debil la relacion lineal  "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20d2f962-fcfa-434c-88ab-12dc05071b03","_uuid":"1e2cb2cce7d8edf2ecd13a7197063ef3eea8d073","colab":{"base_uri":"https://localhost:8080/","height":580},"id":"Nmn-hGsYfaME","outputId":"8ababed3-407d-4371-92e5-84fe65438185","scrolled":true},"outputs":[],"source":["#Matriz de correlación\n","corr = df.corr()\n","corr = (corr)\n","sns.heatmap(corr, \n","            xticklabels=corr.columns.values,\n","            yticklabels=corr.columns.values)\n","corr\n","\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"fd10e1bc-1cca-4bdd-a8b4-73a6b7f5ddd7","_uuid":"06467f1691005e605af9084ee142fd2c86b4f324","id":"EXwS5-erfaMH"},"source":["###  3.2 Gráficos de distribución \n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":550},"id":"xnCHOWV3xTCD","outputId":"509474b4-7fab-4edd-d1dc-3eb6a5865d92"},"outputs":[],"source":["#hist es un grafico (pandas) de distribucion de  datos.\n","#este grafico nos sirve para identificar cuales son las variables numericas y su frencuencia. \n","\n","df.hist(figsize=(16,10),facecolor='blue', alpha=0.9, bins=13, edgecolor='orange', linewidth=2)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1899ace3-af9c-45aa-a351-affc1268f6fd","_uuid":"965942ee9773a202172d7d855495089165b5ddac","colab":{"base_uri":"https://localhost:8080/","height":463},"id":"DSyptdoCfaMI","outputId":"e531a3c8-2d54-49bd-ead4-1effc6548cd7"},"outputs":[],"source":["#otra forma de ver la distribucion de los datos\n","# Uso de Libreria Seaborn (sna) para poner multiples graficos de distribución  \n","f, axes = plt.subplots(ncols=3, figsize=(15, 6))\n","\n","#variable PM10\n","sns.distplot(df.PM10, kde=False, color=\"g\", ax=axes[0]).set_title('PM10')\n","\n","#variable PM10\n","sns.distplot(df.Status, kde=False, color=\"r\", ax=axes[1]).set_title('Status')\n","\n","#variable NOX\n","sns.distplot(df.NOX, kde=False, color=\"b\", ax=axes[2]).set_title('NOX')"]},{"cell_type":"markdown","metadata":{"_cell_guid":"59946601-f880-492f-bba0-2abb6fa3349c","_uuid":"0a7acbd87733d69cd9415694ecf9207bd3a351d8","id":"sWcK6sbxfaMI"},"source":["###  3.3 Gráfico de barras\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9949ba1f-4427-422b-99ca-8dac582a02b1","_uuid":"df172af0f3fc0fdcf837b6f94c0f477fd831dc04","colab":{"base_uri":"https://localhost:8080/","height":283},"id":"kKjM2tlLfaMI","outputId":"05c7e2b3-6947-4b2f-b7eb-159d913641bd","scrolled":true},"outputs":[],"source":["#ditribucion por estacion \n","f, ax = plt.subplots(figsize=(15, 4))\n","sns.countplot(x=\"Station\", hue='Status', data=df).set_title('Distribución de Station');"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3b1f718-f4d4-4e4f-8e64-e110e65416d6","_uuid":"2fa4f8c2ee0138b1a32a5b64611ae2fc1362227d","colab":{"base_uri":"https://localhost:8080/","height":346},"id":"PvGad6_cfaMJ","outputId":"bfb4cc61-25af-4cc9-bb03-a18f4b164bac"},"outputs":[],"source":["# Types of colors\n","color_types = ['#78C850','#F08030','#6890F0','#A8B820','#A8A878','#A040A0','#F8D030',  \n","                '#E0C068','#EE99AC','#C03028','#F85888','#B8A038','#705898','#98D8D8','#7038F8' ,'#FFFFF']\n","\n","# Count Plot (a.k.a. Bar Plot)\n","sns.countplot(y='Station', data=df).set_title('Distribución por Estación');\n"," \n","# Rotate x-labels\n","plt.xticks(rotation=-45)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5c692223-97b5-49e0-91b6-110b14267dad","_uuid":"82a9fc8e7ca4c2d4d7f89921bbf25863ab1b5e0b","id":"t_y8BlNCfaMM"},"source":["###  3.4 Gráficos de Cajas\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f71fe174-dd36-43a2-b882-99976b1fbb8d","_uuid":"8cb12be2d8182a91b87bb91a11edf9864677976d","colab":{"base_uri":"https://localhost:8080/","height":529},"id":"m-HHyXDVfaMO","outputId":"05821c7d-0e14-45a4-f9f0-95f057371e4a","scrolled":true},"outputs":[],"source":["import seaborn as sns\n","\n","a4_dims = (11.7, 8.27)\n","fig, ax = plt.subplots(figsize=a4_dims)\n","\n","sns.boxplot(x=\"Station\", y=\"PM2.5\",  data=df)\n","valh=4\n","plt.axhline(valh, color='red')"]},{"cell_type":"markdown","metadata":{"id":"MUpSVz-3YfQF"},"source":["Hemos revisado la información de ded dataset \"calidad del aire\", donde es importante la estación que mide la calidad del aire, sin embargo, no tenemos donde esta ubicada. \n","\n","Ahora vamos a cargar un nuevo dataset, que contiene la infromación de la ubicación (Latitud, Longitud) de cada estación."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbLMpWpxZMzj","outputId":"62ea56b3-c293-4f45-8cb3-6fde83a21666"},"outputs":[],"source":["#Contar valores nulos por columnas\n","df.isnull().sum()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTurOwAP2D9U","outputId":"929ad3fa-c690-44e1-c135-2f481fabe696"},"outputs":[],"source":["## Hay 74803 valores NaN de 166440\n","nan_rows = df[df.isnull().any(1)]\n","nan_rows"]},{"cell_type":"markdown","metadata":{"id":"6HcLwRs82D9U"},"source":["## 4. Completar datos con Modelos de Machine Learning"]},{"cell_type":"markdown","metadata":{"id":"B02jR-l52D9V"},"source":["### Instalar Librerias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tUw-v7AG2D9V"},"outputs":[],"source":["#!pip install folium\n","#!pip install sklearn\n","#!pip install matplotlib\n","#!pip install seaborn"]},{"cell_type":"markdown","metadata":{"id":"4p4pFUed2D9V"},"source":["### Cargar Librerias"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFcSrTRi2D9V"},"outputs":[],"source":["import os, re\n","import numpy as np\n","\n","import pandas as pd\n","\n","import folium \n","from folium.plugins import FastMarkerCluster\n"," \n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","\n","from utils import *\n","\n","from sklearn.model_selection import train_test_split,StratifiedShuffleSplit\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"markdown","metadata":{"id":"t9PFrWUv2D9V"},"source":["### Cargar dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB6aT5OL2D9V","outputId":"9ae6a78a-b567-4fa1-bb2a-87ebe74a8223"},"outputs":[],"source":["#dataframe nombrado \"df\"\n","df = pd.read_csv('../Taller1/data/dataset_with_geo_missing.csv', sep=',', engine='python', encoding='latin1')\n","df.head(3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TTRwdoAT2D9W","outputId":"aa664641-185f-4676-b22b-d8d890f6a5e8"},"outputs":[],"source":["#Para este ejemplo, vamos a llenar con la media todas las filas excepto la de PM2.5\n","df.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zh_RFc_12D9W"},"outputs":[],"source":["df['PM10'].fillna((df['PM10'].mean()), inplace=True)\n","#df['PM2.5'].fillna((df['PM2.5'].mean()), inplace=True) Menos esta columna\n","df['CO'].fillna((df['CO'].mean()), inplace=True)\n","df['NO'].fillna((df['NO'].mean()), inplace=True)\n","df['NO2'].fillna((df['NO2'].mean()), inplace=True)\n","df['NOX'].fillna((df['NOX'].mean()), inplace=True)\n","df['OZONO'].fillna((df['OZONO'].mean()), inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EOhnInTI2D9W","outputId":"884bd313-dbee-489a-beb2-ae736ec2a023"},"outputs":[],"source":["df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"FpiR0S9W2D9W","tags":[]},"source":["## 4.1 Explicando las brechas pequeñas frente a las brechas grandes\n","\n","En el siguiente ejemplo se puede ver el problema que queremos resolver. Tiene una serie de valores para un solo día de mediciones, y allí falta un valor. Coloreamos el valor faltante en rojo.\n","Existen varias opciones para imputar un valor que complete la serie. Algunas son realmente simples, como usar el promedio de todos los puntos conocidos para la variable (ver punto anterior)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzZinL5e2D9W","outputId":"db71fb0f-9b2d-4194-9228-8855477aa061"},"outputs":[],"source":["rows_of_day = df.apply(lambda row : row['month'] == 3 and row['day_month'] == 6 and row['Station']=='7MA', axis=1)\n","single_day_df = df[rows_of_day]\n","figure(figsize=(10, 5), dpi=80)\n","draw_example(single_day_df, [12], False, 'Down period of size 1')"]},{"cell_type":"markdown","metadata":{"id":"vm3BDGbO2D9W"},"source":["Ahora, a veces los períodos de inactividad son más largos que un solo paso de tiempo. En tales casos, completar los valores que faltan puede ser más difícil que en el caso anterior."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EIdcmMya2D9X","outputId":"5bd84dcd-9e35-437d-bae3-15bacc8db1bd"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example(single_day_df, [12, 13, 14, 15], False, 'Down period of size 4')"]},{"cell_type":"markdown","metadata":{"id":"QNh01Fio2D9X"},"source":["#### Ejemplo de un buen ajuste (fit)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pm_fUZSR2D9X","outputId":"3af2e308-7f56-42dd-e126-f49e4bf81fef"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example(single_day_df, [12])"]},{"cell_type":"markdown","metadata":{"id":"4rylnmpa2D9X"},"source":["#### Ejemplo de un mal ajuste (fit)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o0Rs9-V12D9X","outputId":"7096118b-bcea-4f87-e6dd-1d95104919cc"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example(single_day_df, list(range(3, 18)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bkpk-csa2D9X","outputId":"b8c350be-3d95-4ede-c6d5-01a2aa560b22"},"outputs":[],"source":["# This cell will delete all the rows which have Null values\n","target = 'PM2.5'\n","df_with_missing = df.copy()   # Save a copy with missing values\n","df.dropna(subset=[target], inplace=True)\n","df.isnull().sum()"]},{"cell_type":"markdown","metadata":{"id":"cZXS5XgB2D9Y"},"source":["## 4.2 Aplicación del modelo lineal\n","\n","\n","### Dividir en Entrenamiento/Prueba\n","\n","Para entrenar un modelo de regresión lineal, debe dividir sus datos en conjuntos de entrenamiento y prueba. El conjunto de entrenamiento es con lo que creará una línea de mejor ajuste (Best Fit). Luego probará qué tan bien está su modelo comparando las predicciones de su modelo de regresión lineal con los datos reales.\n","\n","<img src=\"img/split_data.png\" alt=\"datos_divididos\" width=\"400\"/>\n","\n","<center><b>Figura 1:</b> División de datos en conjuntos de entrenamiento y prueba </center>\n","\n","Mezclará el conjunto de datos completo y dividirá sus datos de Bogotá en conjuntos de entrenamiento y prueba para la regresión lineal. Esto simulará el caso cuando tenga valores faltantes en sus datos en momentos aleatorios.\n","\n","Divida el conjunto de datos ejecutando la siguiente celda de código:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0DDa4qp2D9Y"},"outputs":[],"source":["# Split into train and test\n","train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"Tfu_kVfh2D9Y"},"source":["### Métricas de evaluación\n","\n","**Las métricas de evaluación lo ayudan a comprender qué están haciendo bien sus modelos y qué les falta.** En general, usará un conjunto de datos para entrenar el modelo (`train_df`), y usará otro conjunto de datos para evaluar el rendimiento del modelo (`test_df`).\n","\n","Puede utilizar el error cuadrático medio (MSE) para evaluar el rendimiento de un modelo cuando la salida es una variable continua, como la concentración de PM2.5.\n","\n","<img src=\"img/MSE.png\" alt=\"MSE\" width=\"250\"/>\n","\n","<center><b>Figura 3:</b> Error cuadrático medio </center>\n","\n","MSE mide la distancia (Figura 3) entre el valor real (puntos grises) y el valor predicho (línea azul), luego penaliza los errores grandes al elevar al cuadrado la distancia. Nuevamente, no se preocupe por los detalles de MSE, solo sepa que es una métrica común para evaluar el rendimiento.\n","\n","MSE no es la única forma de medir el rendimiento de un modelo. Puedes usar otros como:\n","\n","- **Error absoluto medio:** Muy similar a MSE, pero las distancias no están elevadas al cuadrado.\n","- **Coeficiente de determinación**, denotado por R2, es la proporción de la variación en la variable dependiente que es predecible a partir de la variable independiente.\n","\n","\n","<details>\n","  <summary><span style=\"color:blue\">¿Está interesado en las fórmulas? Haga clic aquí</span></summary>\n","$$MSE = \\frac{1}{N} \\sum_{i=1}^{N}{(y_i - pred_i)^2}$$\n","\n","$$MAE = \\frac{1}{N} \\sum_{i=1}^{N}{|y_i - pred_i|}$$\n","    \n","Donde N es el número de muestras en el conjunto de prueba  (`test_df`)\n","    \n","</details>"]},{"cell_type":"markdown","metadata":{"id":"jM7MpAky2D9Y"},"source":["### Estableciendo una línea base\n","\n","Una buena estrategia para entrenar modelos de IA consiste en crear modelos simples que refinas iterativamente hasta obtener un modelo final. Establecer una línea de base sólida es clave en el resto del proceso porque ayuda a determinar si su modelo realmente está aportando algo interesante o simplemente es una pérdida de tiempo y recursos. En nuestro caso, estamos interesados en métodos que nos ayuden a completar los valores que faltan.\n","Entonces, antes de crear su primer modelo que use el aprendizaje automático, utilizará 2 métodos simples para completar los valores faltantes. En el primer método, reemplazará cada valor faltante por la media o la mediana de la variable objetivo; el segundo método utilizará la mediana de cada estación para ese propósito. La implementación es muy sencilla y ya está implementada en Sklearn como uno de los métodos para la imputación de valores faltantes.\n","\n","Tratemos de establecer nuestra línea de base."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfPwA-Ar2D9Y","outputId":"f3ce4994-3830-4130-9e65-c956c7742e2f"},"outputs":[],"source":["regression_scores = {}\n","\n","regression_scores['global_mean'] = missing_values_imputation_mean(train_df, test_df, 'PM2.5')\n","regression_scores['local_mean'] =  missing_values_imputation_mean_by_station(train_df, test_df,'PM2.5')    \n","\n","print('Desempeño usando la media global')\n","print(regression_scores['global_mean'])\n","print('\\nDesempeño usando la media por estation')\n","print(regression_scores['local_mean'])\n"]},{"cell_type":"markdown","metadata":{"id":"ZMP3XtIF2D9Z"},"source":["### Regresión lineal\n","\n","**El ajuste de curvas** es una excelente forma de modelar datos de series temporales e implica ajustar una función a los datos y usarla para predecir los siguientes valores. Esencialmente, el punto es tratar de encontrar la función matemática que sigue mejor a los puntos de datos.\n","\n","**La regresión lineal** es un tipo de ajuste de curva que intenta modelar la relación entre dos variables o características ajustando una ecuación lineal a los datos. ¡Esencialmente, está tratando de ajustar una línea recta a los datos que tiene!\n","\n","<img src=\"img/linear.png\" alt=\"regresión lineal\" width=\"300\"/>\n","\n","<center><b>Figura 2:</b> Regresión lineal </center>\n","\n","Encontrar la *línea de mejor ajuste* implica usar la ecuación `y = ax + b` que encuentra la relación entre las siguientes variables:\n","- `y`: el eje vertical. Representa PM2.5.\n","- `x`: el eje horizontal. Representa características (por ejemplo, mes, día/semana, hora, etc.).\n","- `a`: la pendiente, que determina el ángulo de la línea. Una pendiente más alta significa que el valor de PM2.5 está aumentando a un *ritmo* más rápido.\n","- `b`: determina qué tan alto o bajo llega la línea al eje y."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohk6Nhbt2D9Z"},"outputs":[],"source":["# You will call this function multiple times in this notebook. Think of this function as a tool which will take the data,\n","# fit into the Linear Regression Model and Evaluate\n","from sklearn.preprocessing import StandardScaler\n","\n","def regression_model(feature_names, target, model):\n","    '''\n","    This function will take the features(x), the target(y) and the model name (Linear Regression)\n","    and will fit the data into the model (train your data using Linear Regression) \n","    and Evaluate by returning the mean squared error and the mean absolute error \n","    '''\n","    scaler = StandardScaler()\n","\n","    #print(f\"Features: {feature_names}\\nTarget: {target}\")\n","    \n","    X_train = train_df[feature_names]\n","    scaler.fit(X_train)\n","    \n","    X_train = scaler.transform(X_train)\n","    y_train = train_df[target]\n","    \n","    X_test = test_df[feature_names]\n","    X_test = scaler.transform(X_test)\n","    \n","    y_test = test_df[target]\n","\n","    # Print out the shapes\n","    #print(f\"\\nX Train Shape:{X_train.shape}\\ny Train Shape: {y_train.shape}\\nX Test Shape: {X_test.shape}\\ny Test Shape: {y_test.shape}\")\n","    \n","    # Build and train model\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","    print(f\"\\nModel Score: {model.score(X_test, y_test)}\")\n","    \n","    return {\"MSE\": mean_squared_error(y_pred, y_test), \"MAE\": mean_absolute_error(y_pred, y_test)}"]},{"cell_type":"markdown","metadata":{"id":"MCk_X5DF2D9Z"},"source":["###  Multilayer Perceptron (MLP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ve1oxg5g2D9Z","outputId":"2f562152-009e-4c96-a53a-e78e3b94b327"},"outputs":[],"source":["from sklearn.neural_network import MLPRegressor\n","\n","model = MLPRegressor(hidden_layer_sizes=(64, 32), learning_rate_init=0.07, verbose=True)\n","regression_scores_MLP = {}\n","target = 'PM2.5'\n","#feature_names = ['hour', 'day_week']\n","    \n","feature_names = ['hour', 'day_week'] +  ['Latitud', 'Longitud'] + ['PM10','CO','NO2','NOX','NO','OZONO']\n","    \n","regression_scores_MLP['model_with_day_hour'] = regression_model(feature_names, target, model)\n","\n","print(regression_scores_MLP['model_with_day_hour'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbfpTqYu2D9Z"},"outputs":[],"source":["from matplotlib.pyplot import figure\n","\n","def draw_example2(sample, predicted2, missing_index):\n","    missing = missing_index\n","    missing_before_after = [missing[0]-1]+missing+[missing[-1]+1]\n","\n","    example1 = sample.copy()\n","    example1.loc[example1['hour'].isin(missing),'PM2.5'] = float('NaN')\n","    plt.plot(missing_before_after,  sample[sample['hour'].isin(missing_before_after)]['PM2.5'] , 'r--o')\n","\n","    example1['newPM2.5'] = example1['PM2.5'].interpolate(method='linear')\n","\n","    plt.plot(missing_before_after, example1[example1['hour'].isin(missing_before_after)]['newPM2.5'], 'g--o')\n","    plt.plot(example1['hour'], example1['PM2.5'], '-*')\n","    \n","    example1['nnPM2.5'] = sample['PM2.5'].copy()\n","    example1.loc[example1['hour'].isin(missing), 'nnPM2.5'] = predicted2[np.array(missing)-1]\n","    plt.plot(missing_before_after, example1.loc[example1['hour'].isin(missing_before_after)]['nnPM2.5'], 'y--*')\n","    \n","    plt.xlabel('hour')\n","    plt.ylabel('PM2.5')\n","    plt.title('Single day real data and predictions')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zIVBQ7s42D9a","outputId":"4b5cc361-1f22-464b-a419-e740b94a781d"},"outputs":[],"source":["#rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 3 and row['Station']=='USQ', axis=1)\n","rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 6 and row['Station']=='USQ', axis=1)\n","\n","single_day_df = df[rows_of_day]\n","\n","scaler = StandardScaler()\n","X_train = train_df[feature_names]\n","scaler.fit(X_train)\n","\n","X_test = single_day_df[feature_names]\n","X_test = scaler.transform(X_test)\n","y_test = single_day_df[target]\n","\n","y_predicted = model.predict(X_test)\n","#y_predicted_DT = model.predict(X_test)\n","\n","figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df, y_predicted, [12])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-S4eeAI2D9a","outputId":"0d121598-57e5-444d-95dc-bc4938babcc7"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df,y_predicted, list(range(3, 18)))"]},{"cell_type":"markdown","metadata":{"id":"dfxbNaLk2D9a"},"source":["### Probando con Árbol de Decisión "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVWugpiw2D9a","outputId":"ba6636df-94d8-4d68-f943-a3398a099c1f"},"outputs":[],"source":["from sklearn import tree\n","\n","model = tree.DecisionTreeRegressor()\n","regression_scores_DT = {}\n","target = 'PM2.5'\n","#feature_names = ['hour', 'day_week']\n","    \n","feature_names = ['hour', 'day_week'] +  ['Latitud', 'Longitud'] + ['PM10','CO','NO2','NOX','NO','OZONO']\n","    \n","regression_scores_DT['model_with_day_hour'] = regression_model(feature_names, target, model)\n","\n","print(regression_scores_DT['model_with_day_hour'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kz0xEx2S2D9a","outputId":"6c203c25-12af-4948-cc8a-10450f8d45ac"},"outputs":[],"source":["#rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 3 and row['Station']=='USQ', axis=1)\n","rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 6 and row['Station']=='USQ', axis=1)\n","\n","single_day_df = df[rows_of_day]\n","\n","scaler = StandardScaler()\n","X_train = train_df[feature_names]\n","scaler.fit(X_train)\n","\n","X_test = single_day_df[feature_names]\n","X_test = scaler.transform(X_test)\n","y_test = single_day_df[target]\n","\n","y_predicted = model.predict(X_test)\n","#y_predicted_DT = model1.predict(X_test)\n","\n","figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df, y_predicted, [12])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6WIzRaxa2D9b","outputId":"1cb18994-964c-46d2-ee51-17c5a4a4bb16"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df,y_predicted, list(range(3, 18)))"]},{"cell_type":"markdown","metadata":{"id":"yhDjJbX82D9b"},"source":["## 4.3 Ajuste de parámetros, Búsqueda por cuadrícula, Validación cruzada\n","\n","Los hiperparámetros son parámetros ajustables que permiten controlar el proceso de entrenamiento de un modelo. Por ejemplo, con redes neuronales, puede decidir el número de capas ocultas y el número de nodos de cada capa. ...El rendimiento de un modelo depende en gran medida de los hiperparámetros.\n","\n","Es posible y recomendable buscar en el espacio de hiperparámetros para obtener la mejor validación cruzada, es decir, evaluar la puntuación de rendimiento del modelo.\n","\n","Cualquier parámetro proporcionado al construir un modelo puede optimizarse de esta manera. Específicamente, para encontrar los nombres y los valores actuales de todos los parámetros para un modelo dado, podemos usar el siguiente método\n","\n","estimator.get_params ()\n","\n","Una búsqueda consta de:\n","\n","* un modelo (regresor o clasificador como sklearn.svm.SVC ());\n","* un espacio de parámetros;\n","* un método para buscar o muestrear candidatos;\n","* un esquema de validación cruzada;\n","* una función de puntuación - metrica.\n","\n","Algunos modelos permiten estrategias de búsqueda de parámetros especializadas y eficientes, que se describen a continuación.\n","\n","En scikit-learn se proporcionan dos enfoques genéricos para muestrear candidatos de búsqueda:\n","\n","\n","<img src=\"https://developer.qualcomm.com/sites/default/files/attachments/learning_resources_03-05.png\" width=\"500\" height=\"270\" >\n","\n","\n","**GridSearchCV:** La búsqueda de cuadrícula proporcionada por GridSearchCV genera exhaustivamente candidatos a partir de una cuadrícula de valores de parámetros especificados con el parámetro param_grid. Por ejemplo, el siguiente param_grid especifica que tiene una cuadrícula para explorar que es un núcleo lineal con valores alfa en [0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0009] y 'max_iter', es decir, un máximo de 10000 iteraciones.\n","\n","param_grid = {'alpha':[0.01,0.001,0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0009],'max_iter':[10000]}\n","\n","**RandomizedSearchCV:** puede muestrear un número determinado de candidatos de un espacio de parámetros con una distribución específica. Después de describir estas herramientas, detallamos las mejores prácticas aplicables a ambos enfoques.\n","\n","Tenga en cuenta que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejarse con sus valores predeterminados. Se recomienda leer la cadena de documentación de la clase de estimador para comprender mejor su comportamiento esperado.\n"]},{"cell_type":"markdown","metadata":{"id":"oGb21r1f2D9b"},"source":["### 6.1 Búsqueda aleatoria/Random Search\n","\n","En la búsqueda aleatoria, creamos una cuadrícula de hiperparámetros y entrenamos / probamos nuestro modelo en una combinación aleatoria de estos hiperparámetros. En este ejemplo, también decidí realizar una validación cruzada en el conjunto de entrenamiento.\n","\n","Al realizar tareas de aprendizaje automático, generalmente dividimos nuestro conjunto de datos en conjuntos de entrenamiento y de prueba. Esto se hace para probar nuestro modelo después de haberlo entrenado (de esta manera podemos verificar su rendimiento cuando trabajamos con datos invisibles). Cuando usamos la validación cruzada, dividimos nuestro conjunto de entrenamiento en otras N particiones para asegurarnos de que nuestro modelo no sobreajuste nuestros datos.\n","\n","Uno de los métodos de validación cruzada más utilizados es la **validación de K-Fold**. En K-Fold, dividimos nuestro conjunto de entrenamiento en N particiones y luego entrenamos iterativamente nuestro modelo usando N-1 particiones y lo probamos con la partición sobrante (en cada iteración cambiamos la partición sobrante). Una vez que hemos entrenado N veces el modelo, promediamos los resultados de entrenamiento obtenidos en cada iteración para obtener nuestros resultados de rendimiento de entrenamiento general.\n","\n","\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f2/K-fold_cross_validation.jpg\" width=\"500\" height=\"270\" >\n","\n","El uso de la validación cruzada al implementar la optimización de hiperparámetros puede ser realmente importante. De esta manera, podríamos evitar el uso de algunos hiperparámetros que funcionan muy bien con los datos de entrenamiento pero no tan bien con los datos de prueba.\n","Ahora podemos comenzar a implementar la búsqueda aleatoria desafiando primero una cuadrícula de hiperparámetros que se muestrearán aleatoriamente al llamar a RandomizedSearchCV ()."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dmz7z5k62D9b"},"outputs":[],"source":["#Librerias \n","from sklearn import tree\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import RandomizedSearchCV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0eRymyo2D9b","outputId":"97842cb3-9c24-4bf3-b667-5f3b9eb4f446"},"outputs":[],"source":["\n","\n","scaler = StandardScaler()\n","\n","    #print(f\"Features: {feature_names}\\nTarget: {target}\")\n","    \n","X_train = train_df[feature_names]\n","scaler.fit(X_train)\n","    \n","X_train = scaler.transform(X_train)\n","y_train = train_df[target]\n","    \n","X_test = test_df[feature_names]\n","X_test = scaler.transform(X_test)\n","    \n","y_test = test_df[target]\n","\n","random_search = {\n","               'max_depth': [2,3,4,20],\n","               'max_features': ['log2', 'sqrt'],\n","               'min_samples_leaf': [2,4, 6, 8],\n","               'min_samples_split': [2, 5, 7,10,20]}\n","kf = KFold(n_splits=2)\n","model = tree.DecisionTreeRegressor()\n","regression_scores_DT_Aleatoria = {}\n","target = 'PM2.5'\n","model_dt = RandomizedSearchCV(estimator = model,  param_distributions = random_search, n_iter = 20, \n","                               cv = 10, verbose=True, random_state= 102, n_jobs = 3)\n","model_dt.fit(X_train, y_train)\n","\n","feature_names = ['hour', 'day_week'] +  ['Latitud', 'Longitud'] + ['PM10','CO','NO2','NOX','NO','OZONO']\n","    \n","regression_scores_DT_Aleatoria['model_with_day_hour'] = regression_model(feature_names, target, model)\n","\n","print(regression_scores_DT_Aleatoria)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMQY0QVx2D9c","outputId":"920771b1-a8ef-4365-9687-cf284f8e3159"},"outputs":[],"source":["#rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 3 and row['Station']=='USQ', axis=1)\n","rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 6 and row['Station']=='USQ', axis=1)\n","\n","single_day_df = df[rows_of_day]\n","\n","scaler = StandardScaler()\n","X_train = train_df[feature_names]\n","scaler.fit(X_train)\n","\n","X_test = single_day_df[feature_names]\n","X_test = scaler.transform(X_test)\n","y_test = single_day_df[target]\n","\n","y_predicted = model_dt.predict(X_test)\n","#y_predicted_DT = model1.predict(X_test)\n","\n","figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df, y_predicted, [12])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9GCfri4v2D9c","outputId":"59b2f0ff-fbb2-4196-8dee-03f4951314a5"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df,y_predicted, list(range(3, 18)))"]},{"cell_type":"markdown","metadata":{"id":"XXB-aiY92D9c"},"source":["### 6.1 Búsqueda cuadrícula/Grid Search\n","\n","En Grid Search, configuramos una cuadrícula de hiperparámetros y entrenamos / probamos nuestro modelo en cada una de las combinaciones posibles.\n","Para elegir los parámetros que se utilizarán en la búsqueda de cuadrícula, ahora podemos ver qué parámetros funcionaron mejor con la búsqueda aleatoria y formar una cuadrícula basada en ellos para ver si podemos encontrar una mejor combinación.\n","\n","- Grid Search se puede implementar en Python usando la función GridSearchCV()."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WEvI06LC2D9c"},"outputs":[],"source":["#Librerias\n","\n","from sklearn.model_selection import GridSearchCV\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anJgRhl62D9c","outputId":"762d6fac-deed-4f6d-e945-c0211126ba3d"},"outputs":[],"source":["grid_search = {\n","               'max_depth': [None, 3, 5, 10],\n","               'max_features': [3, 5, 7, 'sqrt'],\n","               'min_samples_leaf': [2, 4, 6, 8],\n","               'min_samples_split': [2, 5, 7, 10],\n","           \n","               'min_samples_split': [2, 5, 10]\n","               }\n","\n","model = tree.DecisionTreeRegressor()\n","regression_scores_DT_Cuadricula = {}\n","target = 'PM2.5'\n","model_gs = GridSearchCV(estimator = model, param_grid = grid_search, \n","                               cv = 5, verbose= 5, n_jobs = -1)\n","model_gs.fit(X_train,y_train)\n","\n","feature_names = ['hour', 'day_week'] +  ['Latitud', 'Longitud'] + ['PM10','CO','NO2','NOX','NO','OZONO']\n","    \n","regression_scores_DT_Cuadricula['model_with_day_hour'] = regression_model(feature_names, target, model)\n","\n","print(regression_scores_DT_Cuadricula['model_with_day_hour'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_bqUc6C2D9c","outputId":"096c5294-52a2-4983-8b73-fe6181370238"},"outputs":[],"source":["#rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 3 and row['Station']=='USQ', axis=1)\n","rows_of_day = df.apply(lambda row : row['month'] == 11 and row['day_month'] == 6 and row['Station']=='USQ', axis=1)\n","\n","single_day_df = df[rows_of_day]\n","\n","scaler = StandardScaler()\n","X_train = train_df[feature_names]\n","scaler.fit(X_train)\n","\n","X_test = single_day_df[feature_names]\n","X_test = scaler.transform(X_test)\n","y_test = single_day_df[target]\n","\n","y_predicted = model_dt.predict(\n","    X_test)\n","#y_predicted_DT = model1.predict(X_test)\n","\n","figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df, y_predicted, [12])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xSsp_eT-2D9d","outputId":"f6bc65ef-3026-4801-94dc-02031dcf53fa"},"outputs":[],"source":["figure(figsize=(10, 5), dpi=80)\n","draw_example2(single_day_df,y_predicted, list(range(3, 18)))"]},{"cell_type":"markdown","metadata":{"id":"s-Hku8DH2D9d"},"source":["## 4.4 Comparar modelos "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A2x_mS_w2D9d","outputId":"d666a45d-4b6c-4119-cd91-629fd021f1b5"},"outputs":[],"source":["models_cross = pd.DataFrame({\n","    'Model': ['MLP','DT', 'DT Aleatorio', 'DT Cuadricula'],\n","    'MAE': [\n","            regression_scores_MLP['model_with_day_hour']['MAE'],\n","            regression_scores_DT['model_with_day_hour']['MAE'],\n","            regression_scores_DT_Aleatoria['model_with_day_hour']['MAE'],\n","            regression_scores_DT_Cuadricula['model_with_day_hour']['MAE']\n","            \n","           ],\n","    'MSE': [\n","            regression_scores_MLP['model_with_day_hour']['MSE'],\n","            regression_scores_DT['model_with_day_hour']['MSE'],\n","            regression_scores_DT_Aleatoria['model_with_day_hour']['MSE'],\n","            regression_scores_DT_Cuadricula['model_with_day_hour']['MSE']           \n","           ] \n","    })\n"," \n","    \n","    \n","models_cross.sort_values(by='MAE', ascending=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7ni-1h92D9d"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tA8PnMPs2D9d"},"source":["#Implemente su modelo \n","\n"," - Construya un modelo de regresión difrente a los anteriores y configure los parámetros para mejorar el rendimiento de la predicción.  \n"," - Saque al menos dos conclusiones de la implementación de su modelo versus los modelos de este notebook. "]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7 (main, Sep 15 2022, 01:51:29) [Clang 14.0.0 (clang-1400.0.29.102)]"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
